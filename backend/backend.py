#%%
import openai
import os
from rich.console import Console
from dotenv import load_dotenv
from elevenlabs import set_api_key, generate, play, save
from pydub import AudioSegment

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
set_api_key(os.getenv("ELEVENLABS_API_KEY"))
preferences = {
    "preferes_guided_meditation": True,
    "background_sounds": ["seashore", "rain"],
    "duration": "5 minutes"
}

def generate_meditation_text(user_name,goal,  preferences = preferences):
    """Generates a meditation text for a user with a given goal.

    Parameters
    ----------
    user_name : str
        The user's name.
    preferences : str
        User's meditation preferences.
    goal : str
        Goal for the desired meditation.

    Returns
    -------
    str
        Meditation text generated by openai model.
    """
    print(f"Generating meditation for {user_name} with a goal of {goal}")
    prompt = f"Create a personalized meditation script for {user_name} with a goal of {goal}, considering the following preferences: {preferences} in less than 2500 characters"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a meditation expert."},
            {"role": "user", "content": prompt},
        ],
        max_tokens=700,
        temperature=0.7
    )
    meditation_text = response['choices'][0]['message']['content']

    return meditation_text

def generate_voiceover(meditation_text,user_name):
    """Generates a voiceover from meditation text

    Parameters
    ----------
    meditation_text : str
        Meditation text generated by openai model.
    user_name : str
        The user's name.
    """
    audio = generate(
    text= meditation_text,
    voice="Rachel",#"bTJzpYydewofxgh5fyUI",#EXAVITQu4vr4xnSDxMaL", 
    model="eleven_monolingual_v1"
    )

    mp3_file_path = os.path.join(".", "audio_files", f"{user_name}_meditation.mp3")
    save(audio, mp3_file_path)
    return mp3_file_path


def combine_audio_files(voice_audio_path , background_audio_path): 
    voice_audio = AudioSegment.from_mp3(voice_audio_path)
    background_audio = AudioSegment.from_mp3(background_audio_path) - 20

    slow_down_factor = 0.9
    slow_audio = voice_audio._spawn(voice_audio.raw_data, overrides={
    "frame_rate": int(voice_audio.frame_rate * slow_down_factor)
    })
    voice_duration = len(slow_audio)
    background_audio = background_audio[:voice_duration]
    combined_audio = slow_audio.overlay(background_audio)
    combine_audio_filepath = f"./combined_audio/{background_audio_path.split('/')[-1].split('.')[0]}_combined_{voice_audio_path.split('/')[-1]}"
    combined_audio.export(combine_audio_filepath, format="mp3")
    return combine_audio_filepath


# while checking only --------------!------------------
# # Example usage:
# user_name = "John"
# preferences = "peaceful environment, calming music"
# goal = "reduce stress"
# meditation_text = generate_meditation_text(user_name, preferences, goal)
# print(meditation_text)

# # Generate a voiceover for the generated meditation text
# generate_voiceover(meditation_text, user_name)

# # Generate prompt suggestions for meditation
# prompt_suggestions = generate_prompt_suggestions()
# print(prompt_suggestions)
